# ğŸ” Security Policy

This project is an **experimental legal AI tool** for education, research, experimenting and demonstration purposes. It is **not designed for production or deployment in active legal practice environments**. However, we still value responsible disclosure of potential security, law related or integrity issues.

---

## âœ… Supported Components

This project evolves rapidly as Generative AI is evlving. Hereâ€™s the current security support matrix:

| Component                     | Version     | Maintained | Security Reviewed |
|------------------------------|-------------|------------|-------------------|
| LLM Prompting Workflows      | `v2025.1`   | Yes        | Partial           |
| Case Tracker & Metadata CSVs | `v1.0`      | Yes        | âœ… Manually Audited |
| Workflow Automation Scripts  | `v1.0`      | No         | âŒ Experimental    |
| GitHub Actions               | `main`      | Yes        | ğŸŸ¡ Self-Verified   |

---

## ğŸ›¡ï¸ Reporting a Vulnerability

If you discover a security issue or something that compromises the **data logic, model output integrity, or metadata privacy**, please report it immediately.

**Contact:**  
Repo owner : Pradeep Kumar

### ğŸ“¬ Expectations
- We will acknowledge receipt of your report within **72 hours**.
- We will provide a status update every **7 days** while investigating.
- Fixes, if applicable, will be applied in a tagged patch or will be publicly documented with a rationale.

### ğŸš« Notes
This project does **not guarantee real-world legal accuracy** or security enforcement. It is designed to test **generative AI / Large Language Model alignment with legal reasoning in real world case**, not to substitute for legal advice or cybersecurity audits.

---

