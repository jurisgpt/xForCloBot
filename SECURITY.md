# 🔐 Security Policy

This project is an **experimental legal AI tool** for education, research, experimenting and demonstration purposes. It is **not designed for production or deployment in active legal practice environments**. However, we still value responsible disclosure of potential security, law related or integrity issues.

---

## ✅ Supported Components

This project evolves rapidly as Generative AI is evlving. Here’s the current security support matrix:

| Component                     | Version     | Maintained | Security Reviewed |
|------------------------------|-------------|------------|-------------------|
| LLM Prompting Workflows      | `v2025.1`   | Yes        | Partial           |
| Case Tracker & Metadata CSVs | `v1.0`      | Yes        | ✅ Manually Audited |
| Workflow Automation Scripts  | `v1.0`      | No         | ❌ Experimental    |
| GitHub Actions               | `main`      | Yes        | 🟡 Self-Verified   |

---

## 🛡️ Reporting a Vulnerability

If you discover a security issue or something that compromises the **data logic, model output integrity, or metadata privacy**, please report it immediately.

**Contact:**  
Repo owner : Pradeep Kumar

### 📬 Expectations
- We will acknowledge receipt of your report within **72 hours**.
- We will provide a status update every **7 days** while investigating.
- Fixes, if applicable, will be applied in a tagged patch or will be publicly documented with a rationale.

### 🚫 Notes
This project does **not guarantee real-world legal accuracy** or security enforcement. It is designed to test **generative AI / Large Language Model alignment with legal reasoning in real world case**, not to substitute for legal advice or cybersecurity audits.

---

